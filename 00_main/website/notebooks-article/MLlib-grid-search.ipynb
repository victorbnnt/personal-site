{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "58fab4bb-231e-48cf-8ed4-fc15a1b22845",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<h4 style=\"font-variant-caps: small-caps;font-size:35pt;\">MLlib Grid search</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d527e1c-cf68-475c-a5c4-7f5c4fe55ec5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<span><i>Note that the content of this notebook is inspired from the notebook used in the Databricks course <b>Scalable Machine Learning with Apache Sparkâ„¢ (V2)</b> available <a href=\"https://customer-academy.databricks.com/learn/course/1322/scalable-machine-learning-with-apache-spark-v2\" target='_blank'>here</a></i>.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5f6d0da-1d81-4fa0-9770-a9e4d6863534",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<div style='background-color:rgba(30, 144, 255, 0.1);border-radius:5px;padding:2px;'>\n",
    "<span style=\"font-variant-caps: small-caps;font-weight:700\">1. Import libraries</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a2d2e59-7426-4d5f-8d97-3dcff6e5151d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa08db2c-a856-4c86-81fe-9a8b7322cd6a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<div style='background-color:rgba(30, 144, 255, 0.1);border-radius:5px;padding:2px;'>\n",
    "<span style=\"font-variant-caps: small-caps;font-weight:700\">2. Load dataset</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51ff2cfd-eb33-49c6-9097-7837a0faaafd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "amsterdam_airbnb_df_url = \"http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2023-09-03/visualisations/listings.csv\"\n",
    "amsterdam_airbnb_pandas_df = pd.read_csv(amsterdam_airbnb_df_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cec73b82-9578-4943-b05e-5039d16e40e4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<div style='background-color:rgba(30, 144, 255, 0.1);border-radius:5px;padding:2px;'>\n",
    "<span style=\"font-variant-caps: small-caps;font-weight:700\">3. Drop some columns</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "433fc00e-c6c5-4b1b-a34e-a0262330d01b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns_to_exclude = [\"id\",\n",
    "                      \"name\",\n",
    "                      \"host_id\",\n",
    "                      \"host_name\",\n",
    "                      \"neighbourhood_group\",\n",
    "                      \"license\",\n",
    "                      \"last_review\",\n",
    "                      \"reviews_per_month\"]\n",
    "#\n",
    "amsterdam_airbnb_pandas_df = amsterdam_airbnb_pandas_df.drop(columns=columns_to_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3dff730b-6c56-401e-b80e-74d8e17a33b9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<div style='background-color:rgba(30, 144, 255, 0.1);border-radius:5px;padding:2px;'>\n",
    "<span style=\"font-variant-caps: small-caps;font-weight:700\">4. Convert to Spark dataframe</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "015ab04d-21d7-498b-a506-b2b4da8d2624",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"neighbourhood\", StringType(), nullable=True),\n",
    "    StructField(\"latitude\", DoubleType(), nullable=True),\n",
    "    StructField(\"longitude\", DoubleType(), nullable=True),\n",
    "    StructField(\"room_type\", StringType(), nullable=True),\n",
    "    StructField(\"price\", IntegerType(), nullable=True),\n",
    "    StructField(\"minimum_nights\", IntegerType(), nullable=True),\n",
    "    StructField(\"number_of_reviews\", IntegerType(), nullable=True),\n",
    "    StructField(\"calculated_host_listings_count\", IntegerType(), nullable=True),\n",
    "    StructField(\"availability_365\", IntegerType(), nullable=True),\n",
    "    StructField(\"number_of_reviews_ltm\", IntegerType(), nullable=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c60829b-e230-468f-bbdb-cc6d4513e6ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "amsterdam_airbnb_df = spark.createDataFrame(amsterdam_airbnb_pandas_df, schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b595b34-0633-4f66-9ca0-6067f4cc0716",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<div style='background-color:rgba(30, 144, 255, 0.1);border-radius:5px;padding:2px;'>\n",
    "<span style=\"font-variant-caps: small-caps;font-weight:700\">5. Optional: write to delta table</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92c6fbbf-0a08-4fee-8ad7-abdf5a0f9ea4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(amsterdam_airbnb_df.write\n",
    "                    .mode(\"overwrite\")\n",
    "                    .option(\"overwriteSchema\", \"True\")\n",
    "                    .format(\"delta\")\n",
    "                    .saveAsTable(\"amsterdam_airbnb_df\"))\n",
    "#\n",
    "amsterdam_airbnb_df = spark.table(\"amsterdam_airbnb_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50a866b2-29e2-4dad-8c70-0ed707a3202d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<div style='background-color:rgba(30, 144, 255, 0.1);border-radius:5px;padding:2px;'>\n",
    "<span style=\"font-variant-caps: small-caps;font-weight:700\">6. Prepare for ML</span></div>\n",
    "<ul>\n",
    "<li>The exercise here is to make a <b>binary classification</b>. A fake column named <code>priceClass</code> is created from <code>price</code> column. It doesn't make any particular sense. It can take two values - <code>true</code> or <code>false</code> - depending on <code>price</code> above or below <code>150</code>.</li>\n",
    "<li>Note that converting the boolean column to type integer with <code>.cast(\"int\")</code> automatically changes <code>true</code> to <code>1</code> and <code>false</code> to <code>0</code>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dff5f4fd-eb40-4863-a205-4d7b322476a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "airbnb_df = (amsterdam_airbnb_df.withColumn(\"priceClass\", (col(\"price\") >= 150).cast(\"int\"))\n",
    "                                .drop(\"price\"))\n",
    "\n",
    "train_df, test_df = airbnb_df.randomSplit([.8, .2], seed=42)\n",
    "\n",
    "categorical_cols = [field for (field, dataType) in train_df.dtypes if dataType == \"string\"]\n",
    "index_output_cols = [x + \"Index\" for x in categorical_cols]\n",
    "\n",
    "string_indexer = StringIndexer(inputCols=categorical_cols, outputCols=index_output_cols, handleInvalid=\"skip\")\n",
    "\n",
    "numeric_cols = [field for (field, dataType) in train_df.dtypes if ((dataType in [\"double\", \"int\"]) & (field != \"priceClass\"))]\n",
    "assembler_inputs = index_output_cols + numeric_cols\n",
    "vec_assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79ed4d6b-d326-4bd9-a5e3-518cec35431e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<div style='background-color:rgba(30, 144, 255, 0.1);border-radius:5px;padding:2px;'>\n",
    "<span style=\"font-variant-caps: small-caps;font-weight:700\">7. Instantiate ML model: Random Forest classifier</span></div>\n",
    "<ul>\n",
    "<li>The following command let us verify that the minimum number of bins needed for hyperparameter <code>maxBins</code> of <code>RandomForestClassifier</code> model is <code>22</code>. It corresponds to the maximum number of unique values for columns of type string.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95b57340-083d-472d-a861-45caacf51c5e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Column</th><th>Distinct values</th><th>type</th></tr></thead><tbody><tr><td>room_type</td><td>4</td><td>string</td></tr><tr><td>neighbourhood</td><td>22</td><td>string</td></tr><tr><td>calculated_host_listings_count</td><td>17</td><td>int</td></tr><tr><td>minimum_nights</td><td>50</td><td>int</td></tr><tr><td>number_of_reviews_ltm</td><td>141</td><td>int</td></tr><tr><td>availability_365</td><td>366</td><td>int</td></tr><tr><td>number_of_reviews</td><td>485</td><td>int</td></tr><tr><td>price</td><td>631</td><td>int</td></tr><tr><td>latitude</td><td>5865</td><td>double</td></tr><tr><td>longitude</td><td>6845</td><td>double</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "room_type",
         4,
         "string"
        ],
        [
         "neighbourhood",
         22,
         "string"
        ],
        [
         "calculated_host_listings_count",
         17,
         "int"
        ],
        [
         "minimum_nights",
         50,
         "int"
        ],
        [
         "number_of_reviews_ltm",
         141,
         "int"
        ],
        [
         "availability_365",
         366,
         "int"
        ],
        [
         "number_of_reviews",
         485,
         "int"
        ],
        [
         "price",
         631,
         "int"
        ],
        [
         "latitude",
         5865,
         "double"
        ],
        [
         "longitude",
         6845,
         "double"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Column",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Distinct values",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "type",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_distinct = [(column, amsterdam_airbnb_df.select(column).distinct().count(), amsterdam_airbnb_df.select(column).dtypes[0][-1]) for column in amsterdam_airbnb_df.columns]\n",
    "display(spark.createDataFrame(count_distinct, ['Column', 'Distinct values', 'type']).orderBy(['type', 'Distinct values'], ascending=[0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78b6661b-0843-4b7c-bec8-70008a06caea",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<div>Then for the exercise, let's use <code>22</code> as value for <code>maxBins</code> hyperparameter.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "150df3d5-b100-4328-8029-3909b03074e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"priceClass\", maxBins=22, seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54cbaf1e-4273-42f0-9887-90dd18d70383",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<div style='background-color:rgba(30, 144, 255, 0.1);border-radius:5px;padding:2px;'>\n",
    "<span style=\"font-variant-caps: small-caps;font-weight:700\">8. Prepare for Grid Search</span></div>\n",
    "<ul>\n",
    "<li>Defining the grid as shown in the next cell will result in the training of 9 models: There are 3 x 3 parameter combinations.</li>\n",
    "</ul>\n",
    "<a id=\"gridsearch\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b311fb64-2b02-45ff-8b93-725f97f11a42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "grid = (ParamGridBuilder().addGrid(rf.maxDepth, [2, 5, 10])\n",
    "                          .addGrid(rf.numTrees, [10, 20, 100]).build())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f09f30c0-2e06-4634-9d74-79c3bb9fb6c1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<div style='background-color:rgba(30, 144, 255, 0.1);border-radius:5px;padding:2px;'>\n",
    "<span style=\"font-variant-caps: small-caps;font-weight:700\">9. Prepare evaluator</span></div>\n",
    "<ul>\n",
    "<li>The metric chosen here is <code>area under ROC</code>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d4df007-a219-4158-b894-abcb8790772d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "metric = \"areaUnderROC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e45cb79d-3585-4d41-8aa8-882928e48b3b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=\"priceClass\", metricName=metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c11a9853-2e10-40bc-b028-dfd025a5fff5",
     "showTitle": false,
     "title": "--i18n-ea1c0e11-125d-4067-bd70-0bd6c7ca3cdb"
    }
   },
   "source": [
    "<div style='background-color:rgba(30, 144, 255, 0.1);border-radius:5px;padding:2px;'>\n",
    "<span style=\"font-variant-caps: small-caps;font-weight:700\">10. Definition of the Cross Validator</span></div>\n",
    "<ul>\n",
    "<li>Setting <code>numFolds</code> hyperparameter to 3 in the <code>CrossValidator</code> results in the training of 3 models, each of them trained on different set of rows in the dataset. It then results in a score which is the average of the three models scores.</li>\n",
    "<li>When combined with a <b>Grid Search</b>, the number of models trained will be the number of <code>numFolds</code> hyperparameter of the <code>CrossValidator</code> multiplied by the number of <b>Grid Search</b> parameter combinations.</li>\n",
    "<li>Then, in the particular case of this example, there will be 3 x 3 x 3 models to be trained, which is <b>27 models</b>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3d7c3b4-399f-4c17-8986-ddb4d2204ed4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=rf, evaluator=evaluator, estimatorParamMaps=grid, seed=42, numFolds=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16f9e5ed-16a1-44df-94d4-4ffc110b3d40",
     "showTitle": false,
     "title": "--i18n-1f8cebd5-673c-4513-b73b-b64b0a56297c"
    }
   },
   "source": [
    "<div style='background-color:rgba(30, 144, 255, 0.1);border-radius:5px;padding:2px;'>\n",
    "<span style=\"font-variant-caps: small-caps;font-weight:700\">11. Definition of the pipeline and fit the pipeline</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "523e76b7-1e3a-4221-99ba-40432ecef917",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "stages = [string_indexer, vec_assembler, cv]\n",
    "#\n",
    "pipeline = Pipeline(stages=stages)\n",
    "#\n",
    "pipeline_model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62f24580-400e-4b79-8ba1-89a0b80c4ba1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<div style='background-color:rgba(30, 144, 255, 0.1);border-radius:5px;padding:2px;'>\n",
    "<span style=\"font-variant-caps: small-caps;font-weight:700\">12. Get Grid Search parameters value of the best model</span></div>\n",
    "<ul>\n",
    "<li>There are 9 hyperparameters combinations in the <b>Grid Search</b>, thus 9 different model parameterizations.</li>\n",
    "<li>Each of these 9 model parameterization is trained 3 times each time using a different set of data from the dataset, according to the value of <code>numFolds</code> hyperparameter of the <code>CrossValidator</code>.</li>\n",
    "<li>The average of the 3 cross validations for each of the 9 models is the final result.</li>\n",
    "<li>Consequently at the end, 27 models are trained resulting in 9 scores.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b333b7c-f01b-4b74-9d8a-53003d800822",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns_name = [paramName.name for paramName in list(pipeline_model.stages[-1].getEstimatorParamMaps())[0]] + [metric]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "479edf57-320d-498a-ae8d-6f3c0363d182",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<span>Best model is the model with the highest value for <b>area under ROC</b>. It is obtained with the parameters from the <b>Grid Search</b> shown in the first row of the below table.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "581d6ca4-f20c-417b-ab74-50a1b946e102",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>maxDepth</th><th>numTrees</th><th>areaUnderROC</th></tr></thead><tbody><tr><td>10</td><td>100</td><td>0.8407864668331569</td></tr><tr><td>10</td><td>20</td><td>0.8327511187299091</td></tr><tr><td>10</td><td>10</td><td>0.8264245347627136</td></tr><tr><td>5</td><td>100</td><td>0.8207445767017671</td></tr><tr><td>5</td><td>20</td><td>0.8170598033231653</td></tr><tr><td>5</td><td>10</td><td>0.8132904263828932</td></tr><tr><td>2</td><td>100</td><td>0.7509357579175512</td></tr><tr><td>2</td><td>10</td><td>0.7364821016113127</td></tr><tr><td>2</td><td>20</td><td>0.7038806386896654</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         10,
         100,
         "0.8407864668331569"
        ],
        [
         10,
         20,
         "0.8327511187299091"
        ],
        [
         10,
         10,
         "0.8264245347627136"
        ],
        [
         5,
         100,
         "0.8207445767017671"
        ],
        [
         5,
         20,
         "0.8170598033231653"
        ],
        [
         5,
         10,
         "0.8132904263828932"
        ],
        [
         2,
         100,
         "0.7509357579175512"
        ],
        [
         2,
         10,
         "0.7364821016113127"
        ],
        [
         2,
         20,
         "0.7038806386896654"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "maxDepth",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "numTrees",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "areaUnderROC",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sets = [tuple([(v) for k,v in paramset.items()]+[str(avgmetric)]) for paramset,avgmetric in zip(list(pipeline_model.stages[-1].getEstimatorParamMaps()), pipeline_model.stages[-1].avgMetrics)]\n",
    "#\n",
    "display(spark.createDataFrame(sets, columns_name).orderBy(desc(metric)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b189bac-8287-4c93-9a11-46882a1643c8",
     "showTitle": false,
     "title": "--i18n-70cdbfa3-0dd7-4f23-b755-afc0dadd7eb2"
    }
   },
   "source": [
    "<div style='background-color:rgba(30, 144, 255, 0.1);border-radius:5px;padding:2px;'>\n",
    "<span style=\"font-variant-caps: small-caps;font-weight:700\">13. More detailed information related to the best model</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66b30992-fb28-4f93-b059-105f32e84685",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap: Whether bootstrap samples are used when building trees. (default: True)\n",
      "cacheNodeIds: If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. Users can set how often should the cache be checkpointed or disable it by setting checkpointInterval. (default: False)\n",
      "checkpointInterval: set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext. (default: 10)\n",
      "featureSubsetStrategy: The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto' (default: auto)\n",
      "featuresCol: features column name. (default: features)\n",
      "impurity: Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini (default: gini)\n",
      "labelCol: label column name. (default: label, current: priceClass)\n",
      "leafCol: Leaf indices column name. Predicted leaf index of each instance in each tree by preorder. (default: )\n",
      "maxBins: Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature. (default: 32, current: 22)\n",
      "maxDepth: Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30]. (default: 5, current: 10)\n",
      "maxMemoryInMB: Maximum memory in MB allocated to histogram aggregation. If too small, then 1 node will be split per iteration, and its aggregates may exceed this size. (default: 256)\n",
      "minInfoGain: Minimum information gain for a split to be considered at a tree node. (default: 0.0)\n",
      "minInstancesPerNode: Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1. (default: 1)\n",
      "minWeightFractionPerNode: Minimum fraction of the weighted sample count that each child must have after split. If a split causes the fraction of the total weight in the left or right child to be less than minWeightFractionPerNode, the split will be discarded as invalid. Should be in interval [0.0, 0.5). (default: 0.0)\n",
      "numTrees: Number of trees to train (>= 1). (default: 20, current: 100)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "probabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities. (default: probability)\n",
      "rawPredictionCol: raw prediction (a.k.a. confidence) column name. (default: rawPrediction)\n",
      "seed: random seed. (default: -5387697053847413545, current: 42)\n",
      "subsamplingRate: Fraction of the training data used for learning each decision tree, in range (0, 1]. (default: 1.0)\n",
      "thresholds: Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values > 0, excepting that at most one value may be 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class's threshold. (undefined)\n",
      "weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n"
     ]
    }
   ],
   "source": [
    "cv_model = pipeline_model.stages[-1]\n",
    "rf_model = cv_model.bestModel\n",
    "print(rf_model.explainParams())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17cf1a9a-32c7-4e7f-b449-60a56350938f",
     "showTitle": false,
     "title": "--i18n-11e6c47a-ddb1-416d-92a5-2f61340f9a5e"
    }
   },
   "source": [
    "<div style='background-color:rgba(30, 144, 255, 0.1);border-radius:5px;padding:2px;'>\n",
    "<span style=\"font-variant-caps: small-caps;font-weight:700\">14. Features by order of importance</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef34e6ab-0c91-430c-a7ac-3bfb33ebae67",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>room_typeIndex</td>\n",
       "      <td>0.207192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neighbourhoodIndex</td>\n",
       "      <td>0.141898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>number_of_reviews</td>\n",
       "      <td>0.135982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>availability_365</td>\n",
       "      <td>0.127502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>number_of_reviews_ltm</td>\n",
       "      <td>0.107315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>longitude</td>\n",
       "      <td>0.091208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>latitude</td>\n",
       "      <td>0.075542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>minimum_nights</td>\n",
       "      <td>0.068298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>calculated_host_listings_count</td>\n",
       "      <td>0.045064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature</th>\n      <th>importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>room_typeIndex</td>\n      <td>0.207192</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>neighbourhoodIndex</td>\n      <td>0.141898</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>number_of_reviews</td>\n      <td>0.135982</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>availability_365</td>\n      <td>0.127502</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>number_of_reviews_ltm</td>\n      <td>0.107315</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>longitude</td>\n      <td>0.091208</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>latitude</td>\n      <td>0.075542</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>minimum_nights</td>\n      <td>0.068298</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>calculated_host_listings_count</td>\n      <td>0.045064</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pandas_df = pd.DataFrame(list(zip(vec_assembler.getInputCols(), rf_model.featureImportances)), columns=[\"feature\", \"importance\"])\n",
    "top_features = pandas_df.sort_values([\"importance\"], ascending=False)\n",
    "top_features"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 663504876467878,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "MLlib-grid-search",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
